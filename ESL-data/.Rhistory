}
return(ret.mat)
}
mcmc.mat.2parm <- multi.mcmc.2pram()
mcmc.mat.2parm.noburnin <- mcmc.mat.2parm[,(dim(mcmc.mat.2parm)[2]/2):dim(mcmc.mat.2parm)[2],]
par(mfrow=c(2,2))
# trace plot on 2 param
plot(mcmc.mat.2parm.noburnin[1,,1] ~ c(5000:10000), type = "l",xlab = "Iteration", ylab =expression(theta[1]~"|"~theta[2]~y))
hist(mcmc.mat.2parm.noburnin[1,,1], main = "",xlab =expression(theta[1]~"|"~theta[2]~y), ylab = "Frequency")
plot(mcmc.mat.2parm.noburnin[2,,1] ~ c(5000:10000), type = "l",xlab = "Iteration", ylab =expression(theta[2]~"|"~theta[1]~y))
hist(mcmc.mat.2parm.noburnin[2,,1], main = "",xlab =expression(theta[2]~"|"~theta[1]~y), ylab = "Frequency")
# compute the R.hat in this case
R.hat.theta1 <- Gelman.Ruben(mcmc.mat.2parm[1,,])
R.hat.theta2 <- Gelman.Ruben(mcmc.mat.2parm[2,,])
R.hat.theta1
R.hat.theta2
help(plot)
result.list <- MCMC.2parm()
result.list <- MCMC.2parm()
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm
mu_estmat
sd_estmat
plot(x=result.list$theta.1.chosen,
y=result.list$theta.1.chosen,
z=post.sample.2parm)
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm
mu_estmat
sd_estmat
library(ggplot2)
ggplot()+
geom_point(
mapping=aes(x=result.list$theta.1.chosen, y=result.list$theta.2.chosen, color=post.sample.2parm))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm
mu_estmat
sd_estmat
library(ggplot2)
ggplot()+
geom_point(
mapping=aes(x=result.list$theta.1.chosen, y=result.list$theta.2.chosen, color=post.sample.2parm))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
ggplot()+
geom_point(
mapping=aes(x=result.list$theta.1.chosen, y=result.list$theta.2.chosen, color=post.sample.2parm))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
ggplot()+
geom_point(
mapping=aes(x=result.list$theta.1.chosen[5000:10000], y=result.list$theta.2.chosen[5000:1000], color=post.sample.2parm))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
ggplot()+
geom_point(
mapping=aes(x=result.list$theta.1.chosen[5000:10000], y=result.list$theta.2.chosen[5000:10000], color=post.sample.2parm))
data <- data.frame(row.names = c('theta1','theta2','joint_post'))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
data <- data.frame(row.names = c('theta1','theta2','joint_post'))
data['theta1'] <- result.list$theta.1.chosen[5000:10000]
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- data.frame(row.names = c('theta1','theta2','joint_post'))
data['theta1'] <- result.list$theta.1.chosen[5000:10000]
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
#sample.data <- data.frame(row.names = c('theta1','theta2','joint_post'))
data['theta1'] <- result.list$theta.1.chosen[5000:10000]
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- cbind(sample.data,post.sample.2parm)
sample.data <- data.frame(sample.data, row.names = c('theta1','theta2','joint_post'))
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- cbind(sample.data,post.sample.2parm)
sample.data <- as.data.frame(sample.data)
colnames(sample.data) <- c('theta1', 'theta2', 'joint_post')
ggplot()+
geom_point(
mapping=aes(x=theta1, y=theta2, color=joint_post), data=sample.data)
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- cbind(sample.data,post.sample.2parm)
sample.data <- as.data.frame(sample.data)
colnames(sample.data) <- c('theta1', 'theta2', 'joint_post')
ggplot()+
geom_point(
mapping=aes(x=theta1, y=theta2, color=joint_post), data=sample.data)
points(x=mu_estmat, y=sd_estmat, color='red')
help("points")
help("plot)
)
q
q()
quit()
help(plot)
help(aes)
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- cbind(sample.data,post.sample.2parm)
sample.data <- as.data.frame(sample.data)
colnames(sample.data) <- c('theta1', 'theta2', 'joint_post')
ggplot()+
geom_point(
mapping=aes(x=theta1, y=theta2, color=joint_post),size=0.2, data=sample.data)
#points(x=mu_estmat, y=sd_estmat, color='red')
result.list <- MCMC.2parm(10000)
mu_estmat <- mean(result.list$theta.1.chosen)
sd_estmat <- mean(result.list$theta.2.chosen)
post.sample.2parm <- result.list$post.2parm[5000:10000]
mu_estmat
sd_estmat
library(ggplot2)
sample.data <- cbind(result.list$theta.1.chosen[5000:10000],result.list$theta.2.chosen[5000:10000])
sample.data <- cbind(sample.data,post.sample.2parm)
sample.data <- as.data.frame(sample.data)
colnames(sample.data) <- c('theta1', 'theta2', 'joint_post')
ggplot()+
geom_point(
mapping=aes(x=theta1, y=theta2, color=joint_post), data=sample.data)
#points(x=mu_estmat, y=sd_estmat, color='red')
qnorm(0.975,12,3)
qnorm(0.025,12,3)
33/2
17+6
23/2
6 - 1.5*11
17 + 1.5*11
1 - pnorm(14, 12, 3)
pnorm(15,12,3)
1 - pnorm(6, 12, 3)
1 - pnorm(17, 12, 3)
a = 1 - pnorm(17, 12, 3)
a^2
pnorm(17, 12, 3)62
pnorm(17, 12, 3)^2
1 - pnorm(15, 12, 3)^2
pnorm(15, 12, 3)
dbiom(6, 8, 0,84)
dbinom(6, 8, 0,84)
dbinom(6, 8, 0.84)
8.4*0.16
sqrt(1.344)
dpois(0, 3)
dpois(1, 3)
dpois(2, 3)
dpois(3, 3)
dpois(5, 3)
cpois(5, 3)
ppois(1, 3)
.1+.8+.9+.8
.1*(1-2.6)^2 + .4*(0.6)^2 + 0.3*(0.4)^2 + 0.2 * (1.4)^2
sqrt(0.84)
7/40
pnorm(18,15,2) - pnorm(14,15,2)
qnorm(0.975,15,2)
mean(c(15,16,17))
sd(c(15,16,17))
.353/sqrt(40)
20.12+2.125*(2.26/sqrt(40))
20.12-2.125*(2.26/sqrt(40))
2.36*(2.26/.05)
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h')
#--------------------------------------
#--------------------------------------
# Import/Load the rstan library:
library(tidyverse)
library(rstan)
library(loo)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#--------------------------------------
#--------------------------------------
data_in = read.csv('lab8_data.csv')
colnames(data_in) = c('y_obs', 'x_scaled', 'id')
head(data_in,5)
library(ggplot2)
ggplot(data_in, aes(x=x_scaled, y=y_obs)) +
geom_point()
ggplot(data_in, aes(x=x_scaled, y=y_obs, color=factor(id))) +
geom_point()
# define the input data of stan
n_sample = nrow(data_in)
x_vec = data_in$x_scaled
y_vec = data_in$y_obs
stan_data = list(
n_sample=n_sample,
y_vec=y_vec,
x_vec=x_vec)
params_monitor = c("beta", "alpha", "sigma_resid")
# How many samples do we want of each parameter, from each chain?
n_mc_samples = 1000
# How much burn-in?
n_burn = 500
# How much thinning? (take the ith value of the chain)
n_thin = 3
# Total iterations needed:
n_iter_total = (n_mc_samples * n_thin) + n_burn
linear_fit =
stan(file='LinReg.stan',
data=stan_data,
pars=params_monitor,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
install.packages(c("ggplot2", "knitr", "loo", "rstan", "tidyverse"))
install.packages("rstan")
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h')
#--------------------------------------
#--------------------------------------
# Import/Load the rstan library:
library(tidyverse)
library(rstan)
library(loo)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#--------------------------------------
#--------------------------------------
data_in = read.csv('lab8_data.csv')
colnames(data_in) = c('y_obs', 'x_scaled', 'id')
head(data_in,5)
library(ggplot2)
ggplot(data_in, aes(x=x_scaled, y=y_obs)) +
geom_point()
ggplot(data_in, aes(x=x_scaled, y=y_obs, color=factor(id))) +
geom_point()
# define the input data of stan
n_sample = nrow(data_in)
x_vec = data_in$x_scaled
y_vec = data_in$y_obs
stan_data = list(
n_sample=n_sample,
y_vec=y_vec,
x_vec=x_vec)
params_monitor = c("beta", "alpha", "sigma_resid")
# How many samples do we want of each parameter, from each chain?
n_mc_samples = 1000
# How much burn-in?
n_burn = 500
# How much thinning? (take the ith value of the chain)
n_thin = 3
# Total iterations needed:
n_iter_total = (n_mc_samples * n_thin) + n_burn
linear_fit =
stan(file='LinReg.stan',
data=stan_data,
pars=params_monitor,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h')
#--------------------------------------
#--------------------------------------
# Import/Load the rstan library:
library(tidyverse)
library(rstan)
library(loo)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#--------------------------------------
#--------------------------------------
data_in = read.csv('lab8_data.csv')
colnames(data_in) = c('y_obs', 'x_scaled', 'id')
head(data_in,5)
library(ggplot2)
ggplot(data_in, aes(x=x_scaled, y=y_obs)) +
geom_point()
ggplot(data_in, aes(x=x_scaled, y=y_obs, color=factor(id))) +
geom_point()
# define the input data of stan
n_sample = nrow(data_in)
x_vec = data_in$x_scaled
y_vec = data_in$y_obs
stan_data = list(
n_sample=n_sample,
y_vec=y_vec,
x_vec=x_vec)
params_monitor = c("beta", "alpha", "sigma_resid")
# How many samples do we want of each parameter, from each chain?
n_mc_samples = 1000
# How much burn-in?
n_burn = 500
# How much thinning? (take the ith value of the chain)
n_thin = 3
# Total iterations needed:
n_iter_total = (n_mc_samples * n_thin) + n_burn
linear_fit =
stan(file='LinReg.stan',
data=stan_data,
pars=params_monitor,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
summary(model_fit)$summary
summary(linear_fit)$summary
summary(linear_fit)$summary
n_group = length(unique(data_in$id))
n_group = length(unique(data_in$id))
group_idx = data_in$id
stan_data_partial = list(
n_sample=n_sample,
n_group=n_group,
y_vec=y_vec,
x_vec=x_vec,
group_idx=group_idx)
params_monitor_partial = c("beta", "alpha_mean", "eta_alpha", "alpha_sigma",
"sigma_resid")
partial_fit =
stan(file='LinReg.stan',
data=stan_data_partial,
pars=params_monitor_partial,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
n_group = length(unique(data_in$id))
group_idx = data_in$id
stan_data_partial = list(
n_sample=n_sample,
n_group=n_group,
y_vec=y_vec,
x_vec=x_vec,
group_idx=group_idx)
params_monitor_partial = c("beta", "alpha_mean", "eta_alpha", "alpha_sigma",
"sigma_resid")
partial_fit =
stan(file='Intercpets_LinReg.stan',
data=stan_data_partial,
pars=params_monitor_partial,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
n_group = length(unique(data_in$id))
group_idx = data_in$id
stan_data_partial = list(
n_sample=n_sample,
n_group=n_group,
y_vec=y_vec,
x_vec=x_vec,
group_idx=group_idx)
params_monitor_partial = c("beta", "alpha_mean", "eta_alpha", "alpha_sigma",
"sigma_resid")
partial_fit =
stan(file='Intercepts_LinReg.stan',
data=stan_data_partial,
pars=params_monitor_partial,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
summary(partial_fit)$summary
# define the input data of stan
n_sample = nrow(data_in)
x_vec = data_in$x_scaled
y_vec = data_in$y_obs
stan_data = list(
n_sample=n_sample,
y_vec=y_vec,
x_vec=x_vec)
params_monitor = c("beta", "alpha", "sigma_resid",
"log_lik")
# How many samples do we want of each parameter, from each chain?
n_mc_samples = 1000
# How much burn-in?
n_burn = 500
# How much thinning? (take the ith value of the chain)
n_thin = 3
# Total iterations needed:
n_iter_total = (n_mc_samples * n_thin) + n_burn
linear_fit =
stan(file='LinReg.stan',
data=stan_data,
pars=params_monitor,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
summary(linear_fit)$summary
summary(linear_fit)$summary[c("beta","alpha","sigma_resid"),]
n_group = length(unique(data_in$id))
group_idx = data_in$id
stan_data_partial = list(
n_sample=n_sample,
n_group=n_group,
y_vec=y_vec,
x_vec=x_vec,
group_idx=group_idx)
params_monitor_partial = c("beta", "alpha_mean", "eta_alpha", "alpha_sigma",
"sigma_resid", "log_lik")
partial_fit =
stan(file='Intercepts_LinReg.stan',
data=stan_data_partial,
pars=params_monitor_partial,
chains = 3,
warmup = n_burn,
thin = n_thin,
iter = n_iter_total,
algorithm="NUTS")
summary(partial_fit)$summary[c("beta","alpha_mean","sigma_resid","alpha_sigma"),]
summary(partial_fit)$summary[c("beta","alpha_mean","sigma_resid","alpha_sigma","eta_alpha"),]
summary(partial_fit)$summary[c("beta","alpha_mean","sigma_resid","alpha_sigma"),]
log_lik_full = extract_log_lik(linear_fit)
loo_full = loo(log_lik_full)
log_lik_partial = extract_log_lik(partial_fit)
loo_partial = loo(log_lik_partial)
mat = data_frame(as.matrix(c(loo_full$looic, loo_partial$looic)))
colnames(mat) = "looic"
rownames(mat) = c("loo_full_Pooling", "loo_partial_pooling")
mat
log_lik_full = extract_log_lik(linear_fit)
loo_full = loo(log_lik_full)
log_lik_partial = extract_log_lik(partial_fit)
loo_partial = loo(log_lik_partial)
mat = data_frame(as.matrix(c(loo_full$looic, loo_partial$looic)))
colnames(mat) = c("looic")
rownames(mat) = c("loo_full_Pooling", "loo_partial_pooling")
mat
log_lik_full = extract_log_lik(linear_fit)
loo_full = loo(log_lik_full)
log_lik_partial = extract_log_lik(partial_fit)
loo_partial = loo(log_lik_partial)
mat = data_frame(as.matrix(c(loo_full$looic, loo_partial$looic)))
colnames(mat) = c("looic")
rownames(mat) = c("full", "partial")
mat
load("~/Documents/EE599_Machine Learning Research/SVM-Classifier-reproduce-on-python/ESL-data/ESLmixture.rda")
load("~/Documents/EE599_Machine Learning Research/SVM-Classifier-reproduce-on-python/ESL-data/ESLmixture.rda")
setwd("~/Documents/EE599_Machine Learning Research/SVM-Classifier-reproduce-on-python/ESL-data")
xnew = ESL.mixture$xnew
xnew
pred<-predict.logit(xnew)
means = ESL.mixture$means
means
xnew.to_csv()
setwd("~/Documents/EE599_Machine Learning Research/SVM-Classifier-reproduce-on-python/ESL-data")
write.csv(xmeans, file = "ESLxmeans.csv")
write.csv(xnew, file = "ESLxnew.csv")
